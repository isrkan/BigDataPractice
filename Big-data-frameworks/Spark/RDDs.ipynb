{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9488a3be-16a9-45b3-8c82-8637cda304d0",
   "metadata": {},
   "source": [
    "# Exploring movie ratings dataset with Spark RDDs\n",
    "\n",
    "This project focuses on exploring the MovieLens dataset using PySpark RDDs (Resilient Distributed Datasets). RDDs are the fundamental data structure in Spark, offering a distributed way to process large-scale data in parallel across a cluster of machines. In simple terms, RDDs allow us to perform operations on our data, like filtering, transforming, and aggregating, all in parallel. They are fault-tolerant, meaning they can recover automatically from errors, ensuring reliability even in a distributed computing environment.\n",
    "\n",
    "Understanding RDDs is crucial for mastering Spark, especially when fine-grained control over data processing is required.\n",
    "While DataFrame and Spark SQL provide a more high-level and optimized API for structured data processing, RDDs provide a low-level API for performing transformations and data manipulation on distributed data, making them ideal for tasks requiring flexibility and control.\n",
    "\n",
    "##### RDD vs. MapReduce\n",
    "RDD provides a higher-level abstraction compared to MapReduce. RDDs offer a wider range of operations beyond the map and reduce paradigm, including transformations like flatMap, groupByKey, and join. RDD supports iterative and interactive processing patterns more efficiently, making it suitable for machine learning, graph processing, and real-time analytics. MapReduce, on the other hand, primarily used for batch processing tasks, where data is processed in large batches rather than interactively or in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13484ffb-bd03-4b46-9f84-76a80e51b7ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65dd040-05cb-41ed-9048-8cb4c4724936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a SparkConf object to configure Spark. We set the application name to identify our Spark job\n",
    "# We also set the master URL to local[*], indicating that we want to run Spark in local mode using all available CPU cores\n",
    "conf = SparkConf().setAppName(\"RDDExploration\").setMaster(\"local[*]\")\n",
    "# Create a SparkContext object with configuration settings to interact with Spark and to distribute the operations across a cluster\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb774f1-55fb-4986-900d-848608172371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the MovieLens dataset into an rdd where each line in the file becomes an element in the rdd\n",
    "# By loading data into an rdd, Spark can distribute the data across multiple nodes in a cluster, allowing for parallel processing\n",
    "data_rdd = sc.textFile(\"ml-100k/ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125ecfc-b138-45f3-9abd-f9fdf55acbd9",
   "metadata": {},
   "source": [
    "####  Basic RDD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc84f1ff-13e1-4be3-803c-c875813604de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 100000\n"
     ]
    }
   ],
   "source": [
    "# Count determine the number of elements in an rdd\n",
    "num_ratings = data_rdd.count()\n",
    "print(f\"Number of ratings: {num_ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac8a08c-212a-4ec4-ab72-ea9f69931185",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating per movie:\n",
      "Movie ID: 242, Average rating: 3.99\n",
      "Movie ID: 302, Average rating: 4.16\n",
      "Movie ID: 346, Average rating: 3.64\n",
      "Movie ID: 474, Average rating: 4.25\n",
      "Movie ID: 86, Average rating: 3.94\n"
     ]
    }
   ],
   "source": [
    "# Parse each line of the rdd and extract movie id and rating\n",
    "# We use the map transformation to create key-value pairs anf to apply a function to each element of the rdd and transform it into another rdd\n",
    "# First, Split each line of rdd, then create rdd where each element is a tuple containing an integer movie id and a float rating\n",
    "ratings_rdd = data_rdd.map(lambda line: line.split(\"\\t\")[1:3])\n",
    "ratings_rdd = ratings_rdd.map(lambda x: (int(x[0]), float(x[1])))\n",
    "\n",
    "# Calculate the total rating and count per movie\n",
    "# The initial value for each movie is a tuple (0, 0), where the first element represents the total rating and the second element represents the count of ratings\n",
    "# Inside the first lambda, we update the accumulator by adding the rating to the total rating and incrementing the count by 1 for each rating\n",
    "# In the second lambda, we merge the results from different partitions of the RDD. acc1 and acc2 represent accumulators from different partitions\n",
    "movie_rating_counts = ratings_rdd.aggregateByKey((0, 0), lambda acc, rating: (acc[0] + rating, acc[1] + 1), lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1]))\n",
    "# Calculate the average rating per movie. We use the mapValues to apply a function to the values of each key-value pair in the RDD\n",
    "average_rating_per_movie = movie_rating_counts.mapValues(lambda x: x[0] / x[1])\n",
    "\n",
    "print(\"Average rating per movie:\")\n",
    "for movie_id, avg_rating in average_rating_per_movie.take(5):\n",
    "    print(f\"Movie ID: {movie_id}, Average rating: {avg_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd399f9a-fb43-4317-8213-519a848004c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ratings per movie:\n",
      "Movie ID: 242, Number of ratings: 117\n",
      "Movie ID: 302, Number of ratings: 297\n",
      "Movie ID: 346, Number of ratings: 126\n",
      "Movie ID: 474, Number of ratings: 194\n",
      "Movie ID: 86, Number of ratings: 150\n",
      "Number of ratings: 1682\n",
      "\n",
      "Popular movies:\n",
      "Movie ID: 242, Number of ratings: 117\n",
      "Movie ID: 302, Number of ratings: 297\n",
      "Movie ID: 346, Number of ratings: 126\n",
      "Movie ID: 474, Number of ratings: 194\n",
      "Movie ID: 86, Number of ratings: 150\n",
      "Number of ratings: 338\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of ratings per movie\n",
    "total_ratings_per_movie = movie_rating_counts.mapValues(lambda x: x[1])\n",
    "num_ratings = total_ratings_per_movie.count()\n",
    "\n",
    "print(\"Total ratings per movie:\")\n",
    "for movie_id, total_ratings in total_ratings_per_movie.take(5):\n",
    "    print(f\"Movie ID: {movie_id}, Number of ratings: {total_ratings}\")\n",
    "print(f\"Number of ratings: {num_ratings}\")\n",
    "\n",
    "# Filter movies with a minimum number of ratings - here we filter out movies with less than 100 reviews\n",
    "popular_movies = movie_rating_counts.filter(lambda x: x[1][1] >= 100)\n",
    "num_ratings = popular_movies.count()\n",
    "\n",
    "print(\"\\nPopular movies:\")\n",
    "for movie_id, rating_info in popular_movies.take(5):\n",
    "    print(f\"Movie ID: {movie_id}, Number of ratings: {rating_info[1]}\")\n",
    "print(f\"Number of ratings: {num_ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bbf70ba-5d9b-4615-8e3f-4ba1d6929e86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most rated movies:\n",
      "Movie ID: 50, Number of ratings: 583\n",
      "Movie ID: 258, Number of ratings: 509\n",
      "Movie ID: 100, Number of ratings: 508\n",
      "Movie ID: 181, Number of ratings: 507\n",
      "Movie ID: 294, Number of ratings: 485\n",
      "\n",
      "Least rated movies:\n",
      "Movie ID: 1348, Number of ratings: 1\n",
      "Movie ID: 1320, Number of ratings: 1\n",
      "Movie ID: 1492, Number of ratings: 1\n",
      "Movie ID: 1364, Number of ratings: 1\n",
      "Movie ID: 830, Number of ratings: 1\n"
     ]
    }
   ],
   "source": [
    "# Find the most and least rated movies\n",
    "most_rated_movies = movie_rating_counts.map(lambda x: (x[0], x[1][1])).sortBy(lambda x: x[1], ascending=False)\n",
    "least_rated_movies = movie_rating_counts.map(lambda x: (x[0], x[1][1])).sortBy(lambda x: x[1])\n",
    "\n",
    "print(\"Most rated movies:\")\n",
    "for movie_id, num_ratings in most_rated_movies.take(5):\n",
    "    print(f\"Movie ID: {movie_id}, Number of ratings: {num_ratings}\")\n",
    "\n",
    "print(\"\\nLeast rated movies:\")\n",
    "for movie_id, num_ratings in least_rated_movies.take(5):\n",
    "    print(f\"Movie ID: {movie_id}, Number of ratings: {num_ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d846c10-ce08-4bd4-a11d-2850a31bfce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users who rated the most movies:\n",
      "User ID: 50, Number of ratings: 583\n",
      "User ID: 258, Number of ratings: 509\n",
      "User ID: 100, Number of ratings: 508\n",
      "User ID: 181, Number of ratings: 507\n",
      "User ID: 294, Number of ratings: 485\n"
     ]
    }
   ],
   "source": [
    "# Find users who rated the most movies\n",
    "# We assign a count of 1 to each user rating and then use the reduceByKey to aggregate the counts for each user ID\n",
    "user_rating_counts = ratings_rdd.map(lambda x: (x[0], 1)).reduceByKey(lambda x, y: x + y)\n",
    "most_active_users = user_rating_counts.sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "print(\"Users who rated the most movies:\")\n",
    "for user_id, num_ratings in most_active_users.take(5):\n",
    "    print(f\"User ID: {user_id}, Number of ratings: {num_ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d77e95e-bfe9-4d09-9bd2-5bc7d4e88bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating distribution:\n",
      "Rating: 1.0, Count: 6110\n",
      "Rating: 2.0, Count: 11370\n",
      "Rating: 3.0, Count: 27145\n",
      "Rating: 4.0, Count: 34174\n",
      "Rating: 5.0, Count: 21201\n"
     ]
    }
   ],
   "source": [
    "# Find the distribution of ratings and sort by key\n",
    "# We use the countByKey to count the occurrences of each unique key in the RDD (rating value).\n",
    "rating_distribution = ratings_rdd.map(lambda x: (x[1], 1)).countByKey()\n",
    "sorted_rating_distribution = sorted(rating_distribution.items())\n",
    "\n",
    "print(\"Rating distribution:\")\n",
    "for rating, count in sorted_rating_distribution:\n",
    "    print(f\"Rating: {rating}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4b0a4c8-33d9-4bdc-8666-0638f1b3dc25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings by movie:\n",
      "Movie ID: 242, Ratings: [3.0, 3.0, 5.0, 3.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 2.0, 5.0, 5.0, 2.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 2.0, 4.0, 3.0, 5.0, 1.0, 5.0, 5.0, 3.0, 5.0, 1.0, 4.0, 5.0, 3.0, 4.0, 5.0, 4.0, 1.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 3.0, 5.0, 3.0, 5.0, 3.0, 4.0, 4.0, 4.0, 3.0, 5.0, 5.0, 4.0, 5.0, 2.0, 4.0, 5.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 3.0, 4.0, 2.0, 1.0, 5.0, 4.0, 5.0, 3.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 4.0, 3.0]\n",
      "Movie ID: 302, Ratings: [3.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 4.0, 5.0, 4.0, 2.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 3.0, 5.0, 5.0, 1.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 4.0, 3.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 3.0, 5.0, 4.0, 3.0, 3.0, 2.0, 4.0, 4.0, 5.0, 4.0, 5.0, 4.0, 5.0, 2.0, 4.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 3.0, 4.0, 5.0, 5.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 3.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 5.0, 2.0, 5.0, 4.0, 5.0, 3.0, 5.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 3.0, 5.0, 3.0, 5.0, 5.0, 3.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 4.0, 5.0, 2.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 4.0, 4.0, 1.0, 5.0, 4.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 5.0, 3.0, 4.0, 5.0, 3.0, 5.0, 4.0, 3.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 2.0, 2.0, 5.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.0, 4.0, 4.0, 3.0, 5.0, 4.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0, 2.0, 5.0, 5.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 5.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 3.0, 4.0, 5.0, 3.0, 5.0, 4.0, 2.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 5.0, 3.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0, 5.0, 5.0, 3.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 3.0, 4.0]\n",
      "\n",
      "Average rating per movie:\n",
      "Movie ID: 242, Average rating: 3.99\n",
      "Movie ID: 302, Average rating: 4.16\n",
      "Movie ID: 346, Average rating: 3.64\n",
      "Movie ID: 474, Average rating: 4.25\n",
      "Movie ID: 86, Average rating: 3.94\n"
     ]
    }
   ],
   "source": [
    "# Group ratings by movie. We use groupByKey to group ratings by movie ID. The value is a list containing all ratings for that movie\n",
    "ratings_by_movie = ratings_rdd.map(lambda x: (x[0], x[1])).groupByKey()\n",
    "\n",
    "print(\"Ratings by movie:\")\n",
    "for movie_id, ratings_list in ratings_by_movie.take(2):\n",
    "    print(f\"Movie ID: {movie_id}, Ratings: {list(ratings_list)}\")\n",
    "\n",
    "# Group ratings by movie ID and calculate sum and count of ratings for each movie\n",
    "movie_rating_sum_count = ratings_rdd.map(lambda x: (x[0], (x[1], 1))).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "# Calculate average rating for each movie\n",
    "average_rating_per_movie = movie_rating_sum_count.mapValues(lambda x: x[0] / x[1])\n",
    "\n",
    "print(\"\\nAverage rating per movie:\")\n",
    "for movie_id, avg_rating in average_rating_per_movie.take(5):\n",
    "    print(f\"Movie ID: {movie_id}, Average rating: {avg_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c21af3-029e-4a07-aa9a-ccdd4ae18c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of movie_titles_genres_rdd:\n",
      "Movie ID: 1, Title: Toy Story (1995), Genres: 0\n",
      "Movie ID: 2, Title: GoldenEye (1995), Genres: 0\n",
      "Movie ID: 3, Title: Four Rooms (1995), Genres: 0\n",
      "Movie ID: 4, Title: Get Shorty (1995), Genres: 0\n",
      "Movie ID: 5, Title: Copycat (1995), Genres: 0\n",
      "\n",
      "Movies with averaged rating:\n",
      "Movie ID: 40, Average rating: 2.89, Title: To Wong Foo, Thanks for Everything! Julie Newmar (1995), Genres: 0\n",
      "Movie ID: 1184, Average rating: 2.50, Title: Endless Summer 2, The (1994), Genres: 0\n",
      "Movie ID: 392, Average rating: 3.54, Title: Man Without a Face, The (1993), Genres: 0\n",
      "Movie ID: 144, Average rating: 3.87, Title: Die Hard (1988), Genres: 0\n",
      "Movie ID: 768, Average rating: 3.08, Title: Casper (1995), Genres: 0\n"
     ]
    }
   ],
   "source": [
    "# Import movie titles and genres and create key-value pairs with movie ID as key and a tuple of title and genres as value\n",
    "movie_titles_genres_rdd = sc.textFile(\"ml-100k/ml-100k/u.item\").map(lambda line: line.split(\"|\")).map(lambda x: (int(x[0]), (x[1], x[5])))\n",
    "\n",
    "print(\"Values of movie_titles_genres_rdd:\")\n",
    "for movie_id, title_genre_tuple in movie_titles_genres_rdd.take(5):\n",
    "    print(f\"Movie ID: {movie_id}, Title: {title_genre_tuple[0]}, Genres: {title_genre_tuple[1]}\")\n",
    "\n",
    "# Join movie titles and genres with ratings based on movie ID\n",
    "movies_with_ratings = average_rating_per_movie.join(movie_titles_genres_rdd)\n",
    "\n",
    "print(\"\\nMovies with averaged rating:\")\n",
    "for movie_id, (avg_rating, title_genre_tuple) in movies_with_ratings.take(5):\n",
    "    print(f\"Movie ID: {movie_id}, Average rating: {avg_rating:.2f}, Title: {title_genre_tuple[0]}, Genres: {title_genre_tuple[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6502fa3e-fcc7-41e1-bdf4-3b587ab8f508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genres: 2\n",
      "\n",
      "Average rating per genre:\n",
      "Genre: 0, Average rating: 3.08\n",
      "Genre: 1, Average rating: 2.22\n"
     ]
    }
   ],
   "source": [
    "# Extract genres and count distinct values\n",
    "distinct_genres_count = movie_titles_genres_rdd.flatMap(lambda x: x[1][1].split(\",\")).distinct().count()\n",
    "\n",
    "print(f\"Number of genres: {distinct_genres_count}\")\n",
    "\n",
    "# Calculate average rating per genre\n",
    "# map transforms each element into exactly one element, while flatMap can transform each element into zero or more elements\n",
    "# We use flatMap because each movie can belong to multiple genres, so we need to create multiple key-value pairs for each genre associated with the movie\n",
    "# After creating the key-value pairs, we use groupByKey to group the ratings by genre\n",
    "ratings_by_genre = movies_with_ratings.flatMap(lambda x: [(genre, x[1][0]) for genre in x[1][1][1].split(\",\")]).groupByKey()\n",
    "average_rating_per_genre = ratings_by_genre.mapValues(lambda x: sum(x) / len(x))\n",
    "\n",
    "print(\"\\nAverage rating per genre:\")\n",
    "for genre, avg_rating in average_rating_per_genre.take(5):\n",
    "    print(f\"Genre: {genre}, Average rating: {avg_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4547ec61-6bf8-4e3a-999e-b9848f5b0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop SparkContext\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
