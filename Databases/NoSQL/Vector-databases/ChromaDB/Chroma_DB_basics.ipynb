{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chroma DB basics\n",
        "\n",
        "In the rapidly evolving landscape of AI and ML, the ability to efficiently store, search, and retrieve high-dimensional vector data has become crucial. Traditional databases excel at handling structured data with exact matches, but they fall short when dealing with semantic similarity, embeddings, and approximate nearest neighbor searches that are fundamental to modern AI applications.\n",
        "\n",
        "Chroma DB addresses this challenge by providing a vector database that specializes in storing document embeddings and performing semantic similarity searches. Whether we are building a recommendation system, implementing retrieval-augmented generation (RAG) for large language models, or creating content discovery platforms, Chroma DB offers a streamlined solution for managing vector data at scale.\n",
        "\n",
        "This notebook will guide us through Chroma DB's core concepts and practical implementation, starting from basic setup and progressing to advanced features like metadata filtering, custom embedding functions, and production deployment considerations."
      ],
      "metadata": {
        "id": "k7sefCbjE2E4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EEsPbEt0Ey0f"
      },
      "outputs": [],
      "source": [
        "# Install ChromaDB\n",
        "!pip install chromadb\n",
        "\n",
        "# !pip install sentence-transformers  # For better embedding models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChromaDB can operate in different modes - from a simple in-memory database perfect for experimentation to a persistent client-server setup suitable for production environments."
      ],
      "metadata": {
        "id": "QU8FV1QQF7Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import os\n",
        "from typing import List, Dict, Any, cast\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "ZQorkHqZGZGM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Chroma client (in-memory)\n",
        "We will create a ChromaDB client that works in memory, meaning the data won't be saved after the session ends. (If we would like to keep the data saved to disk, we can use the `PersistentClient` instead). This step prepares ChromaDB for storing and searching data later.\n"
      ],
      "metadata": {
        "id": "2zaRJI-5GYgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ChromaDB client (in-memory by default)\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Alternative: Create a persistent client that saves data to disk\n",
        "# client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "print(\"ChromaDB client initialized successfully!\")\n",
        "print(f\"ChromaDB version: {chromadb.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_O8Nri8G7_I",
        "outputId": "9db0ae6b-9f4d-4202-97fd-d76026a8fe24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChromaDB client initialized successfully!\n",
            "ChromaDB version: 1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Client()` constructor creates an in-memory database instance for testing and development. When we need persistence, `PersistentClient()` creates a local database that survives between sessions. The client serves as the main interface for all database operations and manages the connection to ChromaDB's storage engine.\n",
        "\n",
        "### Understanding collections\n",
        "Collections in ChromaDB are analogous to tables in traditional databases, but specifically designed for vector data. Each collection stores documents along with their vector embeddings and optional metadata. Understanding how to create and manage collections is fundamental to working with ChromaDB effectively.\n",
        "\n",
        "Before creating our first collection, let's understand the key concepts:\n",
        "- Documents: The actual text content we want to store and search.\n",
        "- Embeddings: Vector representations of our documents (automatically generated or custom).\n",
        "- Metadata: Additional structured information about each document\n",
        "IDs: Unique identifiers for each document in the collection."
      ],
      "metadata": {
        "id": "9CbDBzn0GeEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new collection\n",
        "collection = client.create_collection(\n",
        "    name=\"my_documents\",\n",
        "    metadata={\"description\": \"A collection of sample documents for learning ChromaDB\"}\n",
        ")\n",
        "\n",
        "# Alternative: switch `create_collection` to `get_or_create_collection` to avoid creating a new collection every time\n",
        "# collection = client.get_or_create_collection(name=\"my_documents\")\n",
        "\n",
        "print(f\"Collection created: {collection.name}\")\n",
        "print(f\"Collection metadata: {collection.metadata}\")\n",
        "print(f\"Collection count: {collection.count()}\")  # Should be 0 initially"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PbFY6TTJK1Z",
        "outputId": "289e8670-f17d-48c6-fed9-dd6b04434375"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection created: my_documents\n",
            "Collection metadata: {'description': 'A collection of sample documents for learning ChromaDB'}\n",
            "Collection count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `create_collection()` method instantiates a new vector space within ChromaDB. The collection object provides methods for adding, querying, and managing documents. ChromaDB automatically handles the underlying vector indexing and storage optimization. The metadata parameter allows us to store collection-level information that can be useful for organization and debugging.\n",
        "\n",
        "Let's also explore how to list and manage existing collections:"
      ],
      "metadata": {
        "id": "UlQu_11bJmuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all collections\n",
        "collections = client.list_collections()\n",
        "print(\"Available collections:\")\n",
        "for col in collections:\n",
        "    print(f\"  - {col.name}: {col.count()} documents\")\n",
        "\n",
        "# Delete a collection (be careful with this!)\n",
        "# client.delete_collection(name=\"my_documents\")\n",
        "\n",
        "# Get an existing collection\n",
        "existing_collection = client.get_collection(name=\"my_documents\")\n",
        "print(f\"\\nRetrieved collection: {existing_collection.name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2jcyA-lJ3SG",
        "outputId": "f7ca469b-a872-4506-8fa6-eb0f12dd1e43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available collections:\n",
            "  - my_documents: 0 documents\n",
            "\n",
            "Retrieved collection: my_documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChromaDB maintains a registry of all collections, which allows for easy discovery and management. The `list_collections()` method returns collection objects, not just names, giving us access to their properties and methods. This design pattern makes it easy to iterate over multiple collections and perform batch operations.\n",
        "\n",
        "### Adding documents to collections\n",
        "Now that we have a collection, let's explore how to add documents. ChromaDB provides flexibility in how we handle embeddings - we can let it generate them automatically using default embedding functions, or provide our own custom embeddings.\n",
        "\n",
        "Understanding the data structure is crucial here. Each document addition requires:\n",
        "- documents: List of text strings\n",
        "- ids: Unique identifiers (strings)\n",
        "- metadatas: Optional list of dictionaries with additional information\n",
        "- embeddings: Optional custom vectors (if not provided, ChromaDB generates them)"
      ],
      "metadata": {
        "id": "IgLDGzHCKBCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample documents for demonstration\n",
        "sample_documents = [\n",
        "    \"ChromaDB is a vector database designed for storing and querying embeddings.\",\n",
        "    \"Machine learning models can convert text into high-dimensional vectors.\",\n",
        "    \"Semantic search allows finding similar content based on meaning rather than keywords.\",\n",
        "    \"Vector databases are essential for modern AI applications like RAG systems.\",\n",
        "    \"Embeddings capture semantic relationships between different pieces of text.\"\n",
        "]\n",
        "\n",
        "# Corresponding metadata for each document\n",
        "sample_metadata = [\n",
        "    {\"category\": \"database\", \"topic\": \"vector_db\", \"difficulty\": \"beginner\"},\n",
        "    {\"category\": \"ml\", \"topic\": \"embeddings\", \"difficulty\": \"intermediate\"},\n",
        "    {\"category\": \"search\", \"topic\": \"semantic\", \"difficulty\": \"intermediate\"},\n",
        "    {\"category\": \"database\", \"topic\": \"ai_applications\", \"difficulty\": \"advanced\"},\n",
        "    {\"category\": \"ml\", \"topic\": \"nlp\", \"difficulty\": \"beginner\"}\n",
        "]\n",
        "\n",
        "# Generate unique IDs for our documents\n",
        "document_ids = [f\"doc_{i+1}\" for i in range(len(sample_documents))]\n",
        "\n",
        "# Add documents to the collection (ChromaDB will generate embeddings automatically)\n",
        "collection.add(\n",
        "    documents=sample_documents,\n",
        "    metadatas=sample_metadata,\n",
        "    ids=document_ids\n",
        ")\n",
        "\n",
        "print(f\"Added {len(sample_documents)} documents to the collection.\")\n",
        "print(f\"Collection now contains {collection.count()} documents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyRTY4H8Kw-w",
        "outputId": "32ebf570-073e-4f6d-8baa-05f1950868d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:01<00:00, 62.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 5 documents to the collection.\n",
            "Collection now contains 5 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we call `add()` without providing embeddings, ChromaDB uses its default collection-level embedding function (typically a sentence transformer model) to generate vector representations of our documents. The embedding process happens automatically and efficiently, with ChromaDB handling the model loading and inference. The metadata is stored alongside the vectors and can be used for both filtering and result enrichment.\n",
        "\n",
        "#### Adding documents to collections with custom embeddings\n",
        "Let's also see how to add documents with custom embeddings:"
      ],
      "metadata": {
        "id": "2xETLx2OLR5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Adding documents with custom embeddings (In practice, we would use a proper embedding model)\n",
        "custom_embeddings = np.random.rand(2, 384).tolist()  # 384-dimensional vectors\n",
        "\n",
        "custom_documents = [\n",
        "    \"This document has a custom embedding vector.\",\n",
        "    \"Another document with manually specified embeddings.\"\n",
        "]\n",
        "\n",
        "custom_ids = [\"custom_1\", \"custom_2\"]\n",
        "custom_metadata = [\n",
        "    {\"source\": \"custom\", \"type\": \"example\"},\n",
        "    {\"source\": \"custom\", \"type\": \"demo\"}\n",
        "]\n",
        "\n",
        "collection.add(\n",
        "    documents=custom_documents,\n",
        "    embeddings=custom_embeddings,\n",
        "    metadatas=custom_metadata,\n",
        "    ids=custom_ids\n",
        ")\n",
        "\n",
        "print(f\"Collection now contains {collection.count()} documents total.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlMya6ZPLtvC",
        "outputId": "0a9c40dc-ab0e-4fe9-b008-5f3e23bee68e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection now contains 7 documents total.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we provide custom embeddings, ChromaDB bypasses its default embedding function and uses our vectors directly. This is useful when we have pre-computed embeddings from specialized models or when we need fine-grained control over the embedding process. The **embedding dimensions must be consistent across all documents in a collection**.\n",
        "\n",
        "### Querying and semantic search\n",
        "The real power of ChromaDB lies in its querying capabilities. Unlike traditional databases that rely on exact matches, ChromaDB performs semantic similarity searches, finding documents that are conceptually similar to our query even if they don't share exact keywords.\n",
        "\n",
        "Understanding query mechanics is essential. ChromaDB converts our query text into an embedding vector, then finds the documents with embeddings closest to our query vector using cosine similarity or other distance metrics."
      ],
      "metadata": {
        "id": "gwqHoqluMHAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic semantic search query\n",
        "query_text = \"What are vector databases used for?\"\n",
        "\n",
        "# Perform a similarity search\n",
        "results = collection.query(\n",
        "    query_texts=[query_text],\n",
        "    n_results=3  # Return top 3 most similar documents\n",
        ")\n",
        "\n",
        "print(f\"Query: '{query_text}'\")\n",
        "print(\"\\nTop 3 similar documents:\")\n",
        "for i, (doc, distance, metadata, doc_id) in enumerate(zip(\n",
        "    results['documents'][0],\n",
        "    results['distances'][0],\n",
        "    results['metadatas'][0],\n",
        "    results['ids'][0]\n",
        ")):\n",
        "    print(f\"\\n{i+1}. Document ID: {doc_id}\")\n",
        "    print(f\"   Distance: {distance:.4f}\")\n",
        "    print(f\"   Category: {metadata['category']}\")\n",
        "    print(f\"   Content: {doc[:100]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4seN15cOMhQg",
        "outputId": "ffcd37eb-f1b4-4e7d-afd0-83512a74888f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'What are vector databases used for?'\n",
            "\n",
            "Top 3 similar documents:\n",
            "\n",
            "1. Document ID: doc_4\n",
            "   Distance: 0.7018\n",
            "   Category: database\n",
            "   Content: Vector databases are essential for modern AI applications like RAG systems....\n",
            "\n",
            "2. Document ID: doc_1\n",
            "   Distance: 0.8530\n",
            "   Category: database\n",
            "   Content: ChromaDB is a vector database designed for storing and querying embeddings....\n",
            "\n",
            "3. Document ID: doc_2\n",
            "   Distance: 1.3882\n",
            "   Category: ml\n",
            "   Content: Machine learning models can convert text into high-dimensional vectors....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `query()` method converts our text into an embedding using the same function used for document ingestion, ensuring consistency. It then performs an approximate nearest neighbor search through the stored vectors, ranking results by similarity score (distance). Lower distance values indicate higher similarity.\n",
        "\n",
        "Let's explore more advanced querying options.\n",
        "\n",
        "#### Metadata filtering\n",
        "Metadata filtering (`where` parameter) applies constraints before the similarity search, effectively creating a subset of documents to search within. This is computationally efficient as it reduces the search space."
      ],
      "metadata": {
        "id": "QmTjIIwHMzlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query with metadata filtering\n",
        "filtered_results = collection.query(\n",
        "    query_texts=[\"machine learning concepts\"],\n",
        "    n_results=5,\n",
        "    where={\"category\": \"ml\"}  # Only return documents with category = \"ml\"\n",
        ")\n",
        "\n",
        "print(\"Filtered query results (ML category only):\")\n",
        "for i, (doc, metadata) in enumerate(zip(\n",
        "    filtered_results['documents'][0],\n",
        "    filtered_results['metadatas'][0]\n",
        ")):\n",
        "    print(f\"{i+1}. {metadata['topic']}: {doc[:80]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj8fjHcXNQQT",
        "outputId": "e8cac06d-2ea1-49f0-a3bb-81d9bad670df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered query results (ML category only):\n",
            "1. embeddings: Machine learning models can convert text into high-dimensional vectors....\n",
            "2. nlp: Embeddings capture semantic relationships between different pieces of text....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChromaDB's filtering system evaluates metadata conditions before performing vector similarity search. This preprocessing step significantly improves query efficiency by reducing the search space.\n",
        "\n",
        "#### Batch querying\n",
        "Batch querying processes multiple queries simultaneously, leveraging vectorized operations for better performance when we have multiple search requests."
      ],
      "metadata": {
        "id": "tYz9HE0NNThT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple queries at once (batch processing)\n",
        "batch_queries = [\n",
        "    \"database technology\",\n",
        "    \"text processing\",\n",
        "    \"artificial intelligence\"\n",
        "]\n",
        "\n",
        "batch_results = collection.query(\n",
        "    query_texts=batch_queries,\n",
        "    n_results=2\n",
        ")\n",
        "\n",
        "print(f\"Batch query results for {len(batch_queries)} queries:\")\n",
        "for query_idx, query in enumerate(batch_queries):\n",
        "    print(f\"\\nQuery: '{query}'\")\n",
        "    for doc_idx, doc in enumerate(batch_results['documents'][query_idx]):\n",
        "        print(f\"  {doc_idx+1}. {doc[:60]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KMdgmiaNEFf",
        "outputId": "b67b6954-d95b-4eaf-f1ea-8f349f6b6b01"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch query results for 3 queries:\n",
            "\n",
            "Query: 'database technology'\n",
            "  1. ChromaDB is a vector database designed for storing and query...\n",
            "  2. Vector databases are essential for modern AI applications li...\n",
            "\n",
            "Query: 'text processing'\n",
            "  1. Machine learning models can convert text into high-dimension...\n",
            "  2. Embeddings capture semantic relationships between different ...\n",
            "\n",
            "Query: 'artificial intelligence'\n",
            "  1. Vector databases are essential for modern AI applications li...\n",
            "  2. Machine learning models can convert text into high-dimension...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced metadata filtering\n",
        "ChromaDB's metadata filtering system provides powerful ways to constrain our searches based on structured information. This capability is crucial for building sophisticated applications that need to combine semantic similarity with specific criteria.\n",
        "Let's explore the various filtering operators and patterns available. ChromaDB supports a MongoDB-like query syntax for metadata filtering, making it intuitive for developers familiar with document databases."
      ],
      "metadata": {
        "id": "fRfaghy4OC95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's add more documents with richer metadata for demonstration\n",
        "extended_documents = [\n",
        "    \"Python is a versatile programming language used in data science.\",\n",
        "    \"JavaScript enables dynamic web applications and user interactions.\",\n",
        "    \"Docker containers provide consistent deployment environments.\",\n",
        "    \"Kubernetes orchestrates containerized applications at scale.\",\n",
        "    \"TensorFlow is a machine learning framework for building neural networks.\",\n",
        "    \"React creates interactive user interfaces for web applications.\"\n",
        "]\n",
        "\n",
        "extended_metadata = [\n",
        "    {\"language\": \"Python\", \"domain\": \"data_science\", \"popularity\": 95, \"year\": 1991},\n",
        "    {\"language\": \"JavaScript\", \"domain\": \"web_development\", \"popularity\": 98, \"year\": 1995},\n",
        "    {\"language\": \"Docker\", \"domain\": \"devops\", \"popularity\": 87, \"year\": 2013},\n",
        "    {\"language\": \"Kubernetes\", \"domain\": \"devops\", \"popularity\": 82, \"year\": 2014},\n",
        "    {\"language\": \"Python\", \"domain\": \"machine_learning\", \"popularity\": 91, \"year\": 1991},\n",
        "    {\"language\": \"JavaScript\", \"domain\": \"web_development\", \"popularity\": 96, \"year\": 1995}\n",
        "]\n",
        "\n",
        "extended_ids = [f\"tech_{i+1}\" for i in range(len(extended_documents))]\n",
        "\n",
        "collection.add(\n",
        "    documents=extended_documents,\n",
        "    metadatas=extended_metadata,\n",
        "    ids=extended_ids\n",
        ")\n",
        "\n",
        "print(f\"Added {len(extended_documents)} more documents. Total: {collection.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd_m97QvOIdV",
        "outputId": "f3cff7b8-5690-4d79-f068-4fb40cc0bba3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 6 more documents. Total: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are adding documents with more complex metadata structures that include different data types (strings, integers) and multiple fields. This creates a richer dataset for demonstrating advanced filtering capabilities.\n",
        "\n",
        "Now let's explore various filtering operators.\n",
        "\n",
        "#### Exact match filtering"
      ],
      "metadata": {
        "id": "l4XBIGeaOdoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exact match filtering\n",
        "python_docs = collection.query(\n",
        "    query_texts=[\"programming language\"],\n",
        "    n_results=10,\n",
        "    where={\"language\": \"Python\"}\n",
        ")\n",
        "\n",
        "print(\"Documents about Python:\")\n",
        "for doc, meta in zip(python_docs['documents'][0], python_docs['metadatas'][0]):\n",
        "    print(f\"  - {meta['domain']}: {doc[:50]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsgR1wfiO3P4",
        "outputId": "7da48401-f318-453e-cbca-1b08225e9056"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents about Python:\n",
            "  - data_science: Python is a versatile programming language used in...\n",
            "  - machine_learning: TensorFlow is a machine learning framework for bui...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numerical comparisons"
      ],
      "metadata": {
        "id": "qVHbDJpUO71E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical comparisons\n",
        "popular_tech = collection.query(\n",
        "    query_texts=[\"technology tools\"],\n",
        "    n_results=10,\n",
        "    where={\"popularity\": {\"$gt\": 90}}  # Popularity greater than 90\n",
        ")\n",
        "\n",
        "print(f\"Popular technologies (>90 popularity):\")\n",
        "for doc, meta in zip(popular_tech['documents'][0], popular_tech['metadatas'][0]):\n",
        "    print(f\"  - {meta['language']} ({meta['popularity']}): {doc[:50]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvf0PvXlO6Mc",
        "outputId": "d62fd0e7-d097-44cd-e050-8ce721e6954d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Popular technologies (>90 popularity):\n",
            "  - JavaScript (98): JavaScript enables dynamic web applications and us...\n",
            "  - JavaScript (96): React creates interactive user interfaces for web ...\n",
            "  - Python (95): Python is a versatile programming language used in...\n",
            "  - Python (91): TensorFlow is a machine learning framework for bui...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The `$gt`, `$gte`, `$lt`, `$lte` operators work with numerical values.\n",
        "\n",
        " #### Multiple conditions"
      ],
      "metadata": {
        "id": "JjMYaShDPB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple conditions with AND logic\n",
        "recent_popular = collection.query(\n",
        "    query_texts=[\"modern technology\"],\n",
        "    n_results=10,\n",
        "    where={\n",
        "        \"$and\": [\n",
        "            {\"popularity\": {\"$gte\": 85}},  # Greater than or equal to 85\n",
        "            {\"year\": {\"$gt\": 2000}}        # Created after 2000\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"Recent and popular technologies:\")\n",
        "for doc, meta in zip(recent_popular['documents'][0], recent_popular['metadatas'][0]):\n",
        "    print(f\"  - {meta['language']} ({meta['year']}): {doc[:50]}...\")\n",
        "\n",
        "\n",
        "# Multiple conditions with OR logic\n",
        "web_or_data_science = collection.query(\n",
        "    query_texts=[\"development frameworks\"],\n",
        "    n_results=10,\n",
        "    where={\n",
        "        \"$or\": [\n",
        "            {\"domain\": \"web_development\"},\n",
        "            {\"domain\": \"data_science\"}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"\\nWeb development or data science documents:\")\n",
        "for doc, meta in zip(web_or_data_science['documents'][0], web_or_data_science['metadatas'][0]):\n",
        "    print(f\"  - {meta['domain']}: {doc[:50]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2EPdBRoOufN",
        "outputId": "d4d44306-6e6b-4bf0-a598-bc3a2826eef9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recent and popular technologies:\n",
            "  - Docker (2013): Docker containers provide consistent deployment en...\n",
            "\n",
            "Web development or data science documents:\n",
            "  - web_development: React creates interactive user interfaces for web ...\n",
            "  - web_development: JavaScript enables dynamic web applications and us...\n",
            "  - data_science: Python is a versatile programming language used in...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `$and` and `$or` operators enable complex logical combinations.\n",
        "\n",
        "#### Inclusion filtering"
      ],
      "metadata": {
        "id": "6dIp88ESPrb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inclusion filtering with $in operator\n",
        "specific_languages = collection.query(\n",
        "    query_texts=[\"programming tools\"],\n",
        "    n_results=10,\n",
        "    where={\"language\": {\"$in\": [\"Python\", \"JavaScript\"]}}\n",
        ")\n",
        "\n",
        "print(f\"\\nPython or JavaScript documents:\")\n",
        "for doc, meta in zip(specific_languages['documents'][0], specific_languages['metadatas'][0]):\n",
        "    print(f\"  - {meta['language']}: {doc[:50]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsuw5f3-QjqE",
        "outputId": "b9505312-d47c-4963-c1c8-e6b0098adf94"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Python or JavaScript documents:\n",
            "  - Python: Python is a versatile programming language used in...\n",
            "  - JavaScript: JavaScript enables dynamic web applications and us...\n",
            "  - Python: TensorFlow is a machine learning framework for bui...\n",
            "  - JavaScript: React creates interactive user interfaces for web ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nested filtering"
      ],
      "metadata": {
        "id": "Hne1h9JIQu9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complex nested conditions\n",
        "complex_filter = collection.query(\n",
        "    query_texts=[\"software development\"],\n",
        "    n_results=10,\n",
        "    where={\n",
        "        \"$and\": [\n",
        "            {\n",
        "                \"$or\": [\n",
        "                    {\"domain\": \"web_development\"},\n",
        "                    {\"domain\": \"devops\"}\n",
        "                ]\n",
        "            },\n",
        "            {\"popularity\": {\"$gte\": 85}}\n",
        "        ]\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"\\nComplex filter results:\")\n",
        "for doc, meta in zip(complex_filter['documents'][0], complex_filter['metadatas'][0]):\n",
        "    print(f\"  - {meta['language']} in {meta['domain']}: {doc[:50]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWv2H2-JQ3ne",
        "outputId": "11cdd47c-d7f1-4100-bb60-808fbd5b446f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Complex filter results:\n",
            "  - JavaScript in web_development: JavaScript enables dynamic web applications and us...\n",
            "  - JavaScript in web_development: React creates interactive user interfaces for web ...\n",
            "  - Docker in devops: Docker containers provide consistent deployment en...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The nested query structure demonstrates ChromaDB's ability to handle complex logical expressions. The query planner optimizes these conditions, often using indexed metadata fields to quickly eliminate non-matching documents before computing similarity scores.\n",
        "\n",
        "### Custom embedding functions\n",
        "While ChromaDB's default embedding function works well for general use cases, we might need custom embedding functions for specialized domains, different languages, or specific model requirements. Understanding how to implement and use custom embedding functions gives us complete control over how our text is vectorized.\n",
        "\n",
        "Custom embedding functions must implement ChromaDB's EmbeddingFunction interface, which defines how text gets converted to vectors. This abstraction allows us to integrate any embedding model while maintaining compatibility with ChromaDB's query system.\n",
        "\n",
        "#### Example 1: Simple custom embedding function using random vectors\n"
      ],
      "metadata": {
        "id": "szXoVyaQQ_Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple custom embedding function using random vectors (In practice, we would use a real embedding model like sentence-transformers)\n",
        "class SimpleEmbeddingFunction(EmbeddingFunction):\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        \"\"\"\n",
        "        Convert documents to embeddings.\n",
        "\n",
        "        Args:\n",
        "            input: List of document strings\n",
        "\n",
        "        Returns:\n",
        "            List of embedding vectors\n",
        "        \"\"\"\n",
        "        embeddings = []\n",
        "        np.random.seed(42)  # For reproducible results in this demo\n",
        "\n",
        "        for doc in input:\n",
        "            # Simple hash-based embedding (don't use in production!)\n",
        "            doc_hash = hash(doc) % 1000000\n",
        "            np.random.seed(doc_hash)\n",
        "            embedding = np.random.rand(384).tolist()  # 384-dimensional vector\n",
        "            embeddings.append(embedding)\n",
        "\n",
        "        return cast(Embeddings, embeddings)\n",
        "\n",
        "# Create a collection with custom embedding function\n",
        "custom_embedding_fn = SimpleEmbeddingFunction()\n",
        "\n",
        "custom_collection = client.create_collection(\n",
        "    name=\"custom_embeddings_demo\",\n",
        "    embedding_function=custom_embedding_fn\n",
        ")\n",
        "\n",
        "print(\"Created collection with custom embedding function\")\n",
        "\n",
        "# Add documents to our simple custom embedding collection\n",
        "test_docs = [\n",
        "    \"Natural language processing enables computers to understand human language.\",\n",
        "    \"Deep learning models can learn complex patterns from large datasets.\",\n",
        "    \"Transformers revolutionized the field of artificial intelligence.\"\n",
        "]\n",
        "\n",
        "custom_collection.add(\n",
        "    documents=test_docs,\n",
        "    ids=[f\"custom_doc_{i}\" for i in range(len(test_docs))],\n",
        "    metadatas=[{\"source\": \"custom_embedding\"} for _ in test_docs]\n",
        ")\n",
        "\n",
        "print(\"Added documents using simple custom embedding function\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAwOFoksRgmx",
        "outputId": "c68c253e-70a3-40a5-985b-7ac207b6d7ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created collection with custom embedding function\n",
            "Added documents using simple custom embedding function\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2746242806.py:26: DeprecationWarning: The class SimpleEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
            "  custom_embedding_fn = SimpleEmbeddingFunction()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `EmbeddingFunction` interface ensures consistency between document ingestion and querying. The `__call__` method receives a list of documents and must return a list of embeddings with consistent dimensions. ChromaDB caches the embedding function with the collection, so queries automatically use the same embedding logic as document ingestion.\n",
        "\n",
        "#### Example 2: Using sentence-transformers for custom embeddings\n",
        "Let's implement a more realistic custom embedding function using sentence-transformers:"
      ],
      "metadata": {
        "id": "HITyrGUfRgIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using sentence-transformers for custom embeddings\n",
        "class SentenceTransformerEmbedding(EmbeddingFunction):\n",
        "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
        "        \"\"\"\n",
        "        Initialize with a specific sentence-transformer model.\n",
        "\n",
        "        Args:\n",
        "            model_name: Name of the sentence-transformer model to use\n",
        "        \"\"\"\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        \"\"\"Generate embeddings using sentence-transformers.\"\"\"\n",
        "        embeddings = self.model.encode(input, convert_to_tensor=False)\n",
        "        return embeddings.tolist()\n",
        "\n",
        "# Create collection with sentence-transformer embeddings\n",
        "st_embedding_fn = SentenceTransformerEmbedding(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "st_collection = client.get_or_create_collection(\n",
        "    name=\"sentence_transformer_demo\",\n",
        "    embedding_function=st_embedding_fn\n",
        ")\n",
        "\n",
        "print(\"Created collection with sentence-transformer embeddings\")\n",
        "\n",
        "# Add some documents to test\n",
        "test_docs = [\n",
        "    \"Natural language processing enables computers to understand human language.\",\n",
        "    \"Deep learning models can learn complex patterns from large datasets.\",\n",
        "    \"Transformers revolutionized the field of artificial intelligence.\"\n",
        "]\n",
        "\n",
        "st_collection.add(\n",
        "    documents=test_docs,\n",
        "    ids=[f\"st_doc_{i}\" for i in range(len(test_docs))],\n",
        "    metadatas=[{\"source\": \"sentence_transformer\"} for _ in test_docs]\n",
        ")\n",
        "\n",
        "print(\"Added documents using sentence-transformer embedding function\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4umXi5DxSjKD",
        "outputId": "310b187e-2779-4da7-db46-cf4a2a3b2415"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created collection with sentence-transformer embeddings\n",
            "Added documents using sentence-transformer embedding function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence-transformers provide advanced embeddings for semantic similarity tasks. The custom embedding function encapsulates model loading and inference, making it reusable across collections. ChromaDB automatically handles the embedding function serialization and ensures consistency between ingestion and query time.\n",
        "\n",
        "#### Query using the custom embedding collection\n",
        "Now let's test our custom embedding function:"
      ],
      "metadata": {
        "id": "Boi3_8hoTucy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query using the custom embedding collection\n",
        "query_result = custom_collection.query(\n",
        "    query_texts=[\"machine learning artificial intelligence\"],\n",
        "    n_results=3\n",
        ")\n",
        "\n",
        "print(\"Query results using custom embedding function:\")\n",
        "for i, (doc, distance) in enumerate(zip(\n",
        "    query_result['documents'][0],\n",
        "    query_result['distances'][0]\n",
        ")):\n",
        "    print(f\"{i+1}. Distance: {distance:.4f}\")\n",
        "    print(f\"   Document: {doc}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5weH5qFaT-zd",
        "outputId": "8ee586d9-7b4c-4512-fd93-9d31f6111172"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query results using custom embedding function:\n",
            "1. Distance: 63.3140\n",
            "   Document: Deep learning models can learn complex patterns from large datasets.\n",
            "\n",
            "2. Distance: 63.3435\n",
            "   Document: Natural language processing enables computers to understand human language.\n",
            "\n",
            "3. Distance: 64.3630\n",
            "   Document: Transformers revolutionized the field of artificial intelligence.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When querying, ChromaDB uses the same embedding function that was used during document ingestion to convert the query text into a vector. This ensures consistency in the vector space and meaningful similarity calculations. The distance values reflect how similar the query embedding is to each document embedding in the high-dimensional space.\n",
        "\n",
        "### Data management and updates\n",
        "Real-world applications require robust data management capabilities. ChromaDB provides methods to update, delete, and retrieve documents efficiently. Understanding these operations is crucial for maintaining dynamic datasets and handling evolving content.\n",
        "\n",
        "Data management in ChromaDB operates on document IDs, making it essential to maintain consistent ID strategies. Let's explore the various data management operations and their implications.\n",
        "\n",
        "#### Get documents in the collection"
      ],
      "metadata": {
        "id": "BgwZSIY8T-Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's check what documents we have in our main collection\n",
        "all_docs = collection.get()\n",
        "print(f\"Current collection contains {len(all_docs['ids'])} documents:\")\n",
        "for doc_id, doc, metadata in zip(all_docs['ids'], all_docs['documents'], all_docs['metadatas']):\n",
        "    print(f\"  {doc_id}: {doc[:50]}... (Category: {metadata.get('category', 'N/A')})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peMGOyMpU382",
        "outputId": "2e363eb1-4c75-482c-d341-dab116a93242"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current collection contains 13 documents:\n",
            "  doc_1: ChromaDB is a vector database designed for storing... (Category: database)\n",
            "  doc_2: Machine learning models can convert text into high... (Category: ml)\n",
            "  doc_3: Semantic search allows finding similar content bas... (Category: search)\n",
            "  doc_4: Vector databases are essential for modern AI appli... (Category: database)\n",
            "  doc_5: Embeddings capture semantic relationships between ... (Category: ml)\n",
            "  custom_1: This document has a custom embedding vector.... (Category: N/A)\n",
            "  custom_2: Another document with manually specified embedding... (Category: N/A)\n",
            "  tech_1: Python is a versatile programming language used in... (Category: N/A)\n",
            "  tech_2: JavaScript enables dynamic web applications and us... (Category: N/A)\n",
            "  tech_3: Docker containers provide consistent deployment en... (Category: N/A)\n",
            "  tech_4: Kubernetes orchestrates containerized applications... (Category: N/A)\n",
            "  tech_5: TensorFlow is a machine learning framework for bui... (Category: N/A)\n",
            "  tech_6: React creates interactive user interfaces for web ... (Category: N/A)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `get()` method without parameters retrieves all documents in the collection. This is useful for inventory management and understanding our dataset's current state. For large collections, we should use filtering or pagination to avoid loading too much data at once.\n",
        "\n",
        "#### Update existing documents in the collection\n",
        "Now let's explore update operations:\n"
      ],
      "metadata": {
        "id": "j697aHdSUpcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's update the first document with new content and metadata\n",
        "updated_document = \"ChromaDB is an advanced vector database optimized for AI applications and semantic search.\"\n",
        "updated_metadata = {\"category\": \"database\", \"topic\": \"vector_db\", \"difficulty\": \"beginner\", \"updated\": True}\n",
        "\n",
        "collection.update(\n",
        "    ids=[\"doc_1\"],\n",
        "    documents=[updated_document],\n",
        "    metadatas=[updated_metadata]\n",
        ")\n",
        "\n",
        "# Verify the update\n",
        "updated_doc = collection.get(ids=[\"doc_1\"])\n",
        "print(\"Updated document:\")\n",
        "print(f\"Content: {updated_doc['documents'][0]}\")\n",
        "print(f\"Metadata: {updated_doc['metadatas'][0]}\")\n",
        "\n",
        "# Update multiple documents at once\n",
        "collection.update(\n",
        "    ids=[\"doc_2\", \"doc_3\"],\n",
        "    metadatas=[\n",
        "        {\"category\": \"ml\", \"topic\": \"embeddings\", \"difficulty\": \"intermediate\", \"batch_updated\": True},\n",
        "        {\"category\": \"search\", \"topic\": \"semantic\", \"difficulty\": \"intermediate\", \"batch_updated\": True}\n",
        "    ]\n",
        "    # Note: Here, we are not updating documents content, only metadata\n",
        ")\n",
        "\n",
        "print(\"\\nBatch updated documents 2 and 3 metadata\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czGP3JjzVOOs",
        "outputId": "bf96d299-e084-4019-aa75-8b328d2f1451"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated document:\n",
            "Content: ChromaDB is an advanced vector database optimized for AI applications and semantic search.\n",
            "Metadata: {'category': 'database', 'topic': 'vector_db', 'updated': True, 'difficulty': 'beginner'}\n",
            "\n",
            "Batch updated documents 2 and 3 metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `update()` method modifies existing documents in-place. When we update a document's text content, ChromaDB automatically regenerates its embedding using the collection's embedding function. Updating only metadata is more efficient as it doesn't require re-embedding. The operation is atomic for each document but not across the entire batch.\n",
        "\n",
        "#### Upsert operation (update if exists, insert if not)\n",
        "Let's explore partial updates and upsert operations:"
      ],
      "metadata": {
        "id": "2DJUtvkGVn9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsert operation (update if exists, insert if not)\n",
        "collection.upsert(\n",
        "    ids=[\"doc_new\", \"doc_1\"],  # doc_new doesn't exist, doc_1 exists\n",
        "    documents=[\n",
        "        \"This is a completely new document added via upsert.\",\n",
        "        \"ChromaDB is a powerful vector database for modern AI workflows.\"  # Updated content for doc_1\n",
        "    ],\n",
        "    metadatas=[\n",
        "        {\"category\": \"example\", \"topic\": \"upsert\", \"difficulty\": \"beginner\"},\n",
        "        {\"category\": \"database\", \"topic\": \"vector_db\", \"difficulty\": \"beginner\", \"upserted\": True}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Performed upsert operation\")\n",
        "print(f\"Collection now has {collection.count()} documents\")\n",
        "\n",
        "# Retrieve specific documents to verify changes\n",
        "specific_docs = collection.get(ids=[\"doc_new\", \"doc_1\"])\n",
        "print(\"\\nDocuments after upsert:\")\n",
        "for doc_id, doc, metadata in zip(specific_docs['ids'], specific_docs['documents'], specific_docs['metadatas']):\n",
        "    print(f\"{doc_id}: {doc[:60]}...\")\n",
        "    print(f\"  Metadata keys: {list(metadata.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToW0x7KfV4Yt",
        "outputId": "f0612ad1-2a90-4c57-db3d-754ba91a3e80"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performed upsert operation\n",
            "Collection now has 14 documents\n",
            "\n",
            "Documents after upsert:\n",
            "doc_1: ChromaDB is a powerful vector database for modern AI workflo...\n",
            "  Metadata keys: ['topic', 'updated', 'category', 'upserted', 'difficulty']\n",
            "doc_new: This is a completely new document added via upsert....\n",
            "  Metadata keys: ['category', 'difficulty', 'topic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsert operations combine the logic of insert and update, making them ideal for scenarios where we are not sure if a document already exists. This is particularly useful in ETL pipelines or when synchronizing data from external sources. ChromaDB determines whether to insert or update based on ID existence.\n",
        "\n",
        "#### Deletion operation\n",
        "Now let's look at deletion operations:"
      ],
      "metadata": {
        "id": "eoLPR6awWGyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete specific documents\n",
        "collection.delete(ids=[\"doc_new\"])\n",
        "print(\"Deleted doc_new\")\n",
        "\n",
        "# Delete documents based on metadata filtering\n",
        "collection.delete(where={\"batch_updated\": True})\n",
        "print(\"Deleted all documents with batch_updated=True\")\n",
        "\n",
        "print(f\"Collection now has {collection.count()} documents\")\n",
        "\n",
        "# Get remaining documents to see what's left\n",
        "remaining = collection.get()\n",
        "print(\"\\nRemaining documents:\")\n",
        "for doc_id in remaining['ids']:\n",
        "    print(f\"  - {doc_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2jaYTO0WTEi",
        "outputId": "4fb9da62-ab68-4975-ec03-630a74dab95f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted doc_new\n",
            "Deleted all documents with batch_updated=True\n",
            "Collection now has 11 documents\n",
            "\n",
            "Remaining documents:\n",
            "  - doc_1\n",
            "  - doc_4\n",
            "  - doc_5\n",
            "  - custom_1\n",
            "  - custom_2\n",
            "  - tech_1\n",
            "  - tech_2\n",
            "  - tech_3\n",
            "  - tech_4\n",
            "  - tech_5\n",
            "  - tech_6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChromaDB supports both ID-based and metadata-based deletion. ID-based deletion is more efficient as it directly targets specific documents. Metadata-based deletion first filters documents matching the criteria, then removes them. Both operations immediately free up storage space and remove documents from the search index.\n",
        "\n",
        "### Collection management and persistence\n",
        "Understanding how ChromaDB handles data persistence and collection lifecycle management is crucial for production deployments. Different persistence modes offer tradeoffs between performance, durability, and resource usage.\n",
        "\n",
        "ChromaDB supports several persistence modes, each suitable for different use cases. Let's explore these options and understand when to use each approach.\n",
        "\n",
        "#### Persistent client\n",
        "We will create a persistent client that saves data to disk. `PersistentClient` creates a local database that writes data to disk immediately. This ensures durability across application restarts and system failures. The database uses an embedded storage engine that handles indexing, compression, and transaction logging automatically."
      ],
      "metadata": {
        "id": "ZSrpSrB3WaFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a temporary directory for our persistent database\n",
        "persistent_path = tempfile.mkdtemp()\n",
        "print(f\"Creating persistent database at: {persistent_path}\")\n",
        "\n",
        "# Initialize persistent client\n",
        "persistent_client = chromadb.PersistentClient(path=persistent_path)\n",
        "\n",
        "# Create a collection in the persistent database\n",
        "persistent_collection = persistent_client.create_collection(\n",
        "    name=\"persistent_demo\",\n",
        "    metadata={\"persistence\": True, \"created_at\": \"2024-01-01\"}\n",
        ")\n",
        "\n",
        "# Add some data to demonstrate persistence\n",
        "demo_docs = [\n",
        "    \"Persistent storage ensures data survives application restarts.\",\n",
        "    \"ChromaDB can operate in both memory and disk-based modes.\",\n",
        "    \"Production applications should use persistent storage for reliability.\"\n",
        "]\n",
        "\n",
        "persistent_collection.add(\n",
        "    documents=demo_docs,\n",
        "    ids=[f\"persistent_{i}\" for i in range(len(demo_docs))],\n",
        "    metadatas=[{\"type\": \"persistence_demo\"} for _ in demo_docs]\n",
        ")\n",
        "\n",
        "print(f\"Added {len(demo_docs)} documents to persistent collection\")\n",
        "print(f\"Data is stored at: {persistent_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zlXMEmAWqG0",
        "outputId": "1a7340f6-ef33-4cc9-aa75-ff22f865032d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating persistent database at: /tmp/tmp5smxktwi\n",
            "Added 3 documents to persistent collection\n",
            "Data is stored at: /tmp/tmp5smxktwi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's demonstrate the persistence by creating a new client instance:"
      ],
      "metadata": {
        "id": "MR_G8vkMWrvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate application restart by creating a new client pointing to the same path\n",
        "new_persistent_client = chromadb.PersistentClient(path=persistent_path)\n",
        "\n",
        "# Retrieve the existing collection\n",
        "recovered_collection = new_persistent_client.get_collection(\"persistent_demo\")\n",
        "\n",
        "print(f\"Recovered collection: {recovered_collection.name}\")\n",
        "print(f\"Document count: {recovered_collection.count()}\")\n",
        "print(f\"Collection metadata: {recovered_collection.metadata}\")\n",
        "\n",
        "# Query the recovered data to verify it's intact\n",
        "recovery_test = recovered_collection.query(\n",
        "    query_texts=[\"database storage\"],\n",
        "    n_results=2\n",
        ")\n",
        "\n",
        "print(\"\\nRecovered documents:\")\n",
        "for doc in recovery_test['documents'][0]:\n",
        "    print(f\"  - {doc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr0PDT0WXagB",
        "outputId": "cdf232ee-0b1d-4699-c15f-aad92991eefc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recovered collection: persistent_demo\n",
            "Document count: 3\n",
            "Collection metadata: {'created_at': '2024-01-01', 'persistence': True}\n",
            "\n",
            "Recovered documents:\n",
            "  - Persistent storage ensures data survives application restarts.\n",
            "  - Production applications should use persistent storage for reliability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you create a new `PersistentClient` with an existing database path, ChromaDB automatically loads the existing data, indexes, and metadata. This demonstrates true persistence - our data survives application restarts without any additional setup or migration steps.\n",
        "\n",
        "Now let's explore advanced collection management:"
      ],
      "metadata": {
        "id": "-kyDCU7EXpaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collection metadata and configuration\n",
        "collection_config = {\n",
        "    \"hnsw:space\": \"cosine\",  # Distance metric for similarity calculations\n",
        "    \"hnsw:construction_ef\": 200,  # Controls index build quality vs speed\n",
        "    \"hnsw:M\": 16  # Controls index connectivity and memory usage\n",
        "}\n",
        "\n",
        "# Create a collection with specific configuration\n",
        "configured_collection = persistent_client.create_collection(\n",
        "    name=\"configured_demo\",\n",
        "    metadata={\n",
        "        \"description\": \"Collection with custom HNSW parameters\",\n",
        "        \"optimization\": \"quality\",\n",
        "        \"created_by\": \"tutorial\",\n",
        "        **collection_config  # Apply the HNSW configuration parameters\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Created collection with custom configuration\")\n",
        "\n",
        "# Inspect collection details\n",
        "collections_info = persistent_client.list_collections()\n",
        "print(f\"\\nAvailable collections in persistent database:\")\n",
        "for col in collections_info:\n",
        "    print(f\"  - {col.name}: {col.count()} documents\")\n",
        "    if hasattr(col, 'metadata') and col.metadata:\n",
        "        print(f\"    Metadata: {col.metadata}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3aDcPWdX2xv",
        "outputId": "fece02da-8627-458c-eb05-9ca049aa4330"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created collection with custom configuration\n",
            "\n",
            "Available collections in persistent database:\n",
            "  - configured_demo: 0 documents\n",
            "    Metadata: {'created_by': 'tutorial', 'hnsw:construction_ef': 200, 'optimization': 'quality', 'description': 'Collection with custom HNSW parameters', 'hnsw:space': 'cosine', 'hnsw:M': 16}\n",
            "  - persistent_demo: 3 documents\n",
            "    Metadata: {'created_at': '2024-01-01', 'persistence': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChromaDB uses HNSW (Hierarchical Navigable Small World) indices for efficient approximate nearest neighbor search. The configuration parameters control the trade-off between search accuracy, build time, and memory usage. Higher values generally improve accuracy at the cost of resources.\n",
        "\n",
        "#### Export and import collection\n",
        "Let's also explore collection backup and migration strategies:\n"
      ],
      "metadata": {
        "id": "-9ZdBeTXekeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export collection data for backup or migration\n",
        "def export_collection(collection, filename):\n",
        "    \"\"\"Export collection data to a dictionary that can be saved.\"\"\"\n",
        "    all_data = collection.get(include=[\"documents\", \"metadatas\", \"embeddings\"])\n",
        "\n",
        "    export_data = {\n",
        "        \"name\": collection.name,\n",
        "        \"metadata\": collection.metadata,\n",
        "        \"documents\": all_data[\"documents\"],\n",
        "        \"metadatas\": all_data[\"metadatas\"],\n",
        "        \"embeddings\": all_data[\"embeddings\"],\n",
        "        \"ids\": all_data[\"ids\"],\n",
        "        \"count\": len(all_data[\"ids\"])\n",
        "    }\n",
        "\n",
        "    # In a real application, you'd save this to JSON or pickle\n",
        "    print(f\"Exported {export_data['count']} documents from collection '{collection.name}'\")\n",
        "    return export_data\n",
        "\n",
        "def import_collection(client, export_data, new_name=None):\n",
        "    \"\"\"Import previously exported collection data.\"\"\"\n",
        "    collection_name = new_name or export_data[\"name\"]\n",
        "\n",
        "    # Create new collection\n",
        "    imported_collection = client.create_collection(\n",
        "        name=collection_name,\n",
        "        metadata=export_data[\"metadata\"]\n",
        "    )\n",
        "\n",
        "    # Add all the data back\n",
        "    if export_data[\"count\"] > 0:\n",
        "        imported_collection.add(\n",
        "            documents=export_data[\"documents\"],\n",
        "            metadatas=export_data[\"metadatas\"],\n",
        "            embeddings=export_data[\"embeddings\"],\n",
        "            ids=export_data[\"ids\"]\n",
        "        )\n",
        "\n",
        "    print(f\"Imported {export_data['count']} documents to collection '{collection_name}'\")\n",
        "    return imported_collection\n",
        "\n",
        "# Demonstrate export/import\n",
        "backup_data = export_collection(persistent_collection, \"backup.json\")\n",
        "\n",
        "# Import to a new collection\n",
        "imported_collection = import_collection(\n",
        "    persistent_client,\n",
        "    backup_data,\n",
        "    new_name=\"imported_demo\"\n",
        ")\n",
        "\n",
        "print(f\"Import successful. New collection has {imported_collection.count()} documents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2swjKRefE6O",
        "outputId": "a887f171-939b-409c-ba7c-3f6b082b15a6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported 3 documents from collection 'persistent_demo'\n",
            "Imported 3 documents to collection 'imported_demo'\n",
            "Import successful. New collection has 3 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The export/import functions provide a way to backup collections or migrate data between ChromaDB instances. The `get()` method with `include=[\"documents\", \"metadatas\", \"embeddings\"]` retrieves all stored data including pre-computed embeddings. This is more efficient than re-computing embeddings during import, especially for large collections."
      ],
      "metadata": {
        "id": "xuP4vl_qfIjb"
      }
    }
  ]
}