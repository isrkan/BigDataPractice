{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDqlBTbvzcd8"
   },
   "source": [
    "## **GPU acceleration in FAISS**\n",
    "\n",
    "FAISS can leverage GPUs to perform computations much faster than on CPUs. FAISS provides a GPU module that allows moving indices and the associated computations to GPUs. This is particularly useful for:\n",
    "- Large-scale datasets with millions of vectors.\n",
    "- Complex indices like IVF or PQ, where GPU parallelism significantly speeds up processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTKOpM4Xzfdb",
    "outputId": "b1dc374d-949e-4b1e-873e-c708182b8701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS version: 1.7.2\n",
      "Has GPU support: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "print(\"FAISS version:\", faiss.__version__)\n",
    "print(\"Has GPU support:\", faiss.get_num_gpus() > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUMaSt15zfsH"
   },
   "source": [
    "### Example : Move an index to GPU\n",
    "Here, we demonstrate how to move an index from the CPU to the GPU and perform a search using the GPU-accelerated index. We will start with a simple IndexFlatL2 example and move it to the GPU.\n",
    "\n",
    "##### Step 1: Generate random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UEhcwfWt7ef2"
   },
   "outputs": [],
   "source": [
    "# Generate a dataset of random vectors\n",
    "dimension = 128\n",
    "num_vectors = 10000\n",
    "data = np.random.random((num_vectors, dimension)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U2YfWOB7et2"
   },
   "source": [
    "##### Step 2: Create a CPU index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3hZv6ZDE7e7Y"
   },
   "outputs": [],
   "source": [
    "# Create a CPU index\n",
    "cpu_index = faiss.IndexFlatL2(dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-K45y0V7fIp"
   },
   "source": [
    "We create an `IndexFlatL2` index on the CPU. This is a simple, brute-force index that computes the L2 (Euclidean) distance to search for the nearest neighbors.\n",
    "\n",
    "##### Step 3: Add data to the CPU index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7tHsl27X7ffz"
   },
   "outputs": [],
   "source": [
    "# Add data to the CPU index\n",
    "cpu_index.add(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hHMGYgg8RBF"
   },
   "source": [
    "We add the dataset (`data`) to the CPU-based index. This index will store all the vectors in memory for fast comparisons during a search.\n",
    "\n",
    "##### Step 4: Move the index to GPU\n",
    "We should move the index to the GPU after creating the index and adding data to it on the CPU. Moving the index to the GPU is done once and after the index is populated with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHa6OjSG8RPa",
    "outputId": "f125cde1-39f9-4280-af90-b6df671187a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index moved to GPU.\n"
     ]
    }
   ],
   "source": [
    "# Move the index to the GPU\n",
    "gpu_index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, cpu_index)\n",
    "print(\"Index moved to GPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fWZH2dJ8Ref"
   },
   "source": [
    "`faiss.index_cpu_to_gpu` is the key function that moves the index from the CPU to the GPU. It requires:\n",
    "- `faiss.StandardGpuResources()`: This specifies the GPU resources FAISS will use.\n",
    "- `0`: This indicates we are using GPU 0 (in case you have multiple GPUs).\n",
    "- `cpu_index`: The index we created on the CPU.\n",
    "\n",
    "After this step, the `gpu_index` is a GPU-accelerated version of the CPU index.\n",
    "\n",
    "##### Step 5: Search on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNKYu-6i8xNN",
    "outputId": "ec9d01c1-66a7-4a2f-aa22-b55b8fc07808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [[7862 1563 2353 3671 3181]]\n"
     ]
    }
   ],
   "source": [
    "# Perform a search on the GPU index\n",
    "query_vector = np.random.random((1, dimension)).astype('float32')\n",
    "distances, indices = gpu_index.search(query_vector, 5)\n",
    "print(\"Indices of nearest neighbors:\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuCcSrKM8xd5"
   },
   "source": [
    "We create a random query vector, similar to the dataset vectors. The `search` function is used to find the nearest neighbors of the query vector in the GPU-based index (`gpu_index`)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
